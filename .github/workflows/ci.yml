name: CI

"on":
  push:
    branches: [master, main, develop]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - 'splunk.wiki/**'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/PULL_REQUEST_TEMPLATE/**'
      - 'LICENSE'
      - '.gitignore'
  pull_request:
    branches: [master, main, develop]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - 'splunk.wiki/**'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/PULL_REQUEST_TEMPLATE/**'
      - 'LICENSE'
      - '.gitignore'

permissions:
  contents: read

env:
  SPLUNK_HOME: /opt/splunk

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  validate-syntax:
    name: Validate Syntax
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Make scripts executable
        run: chmod -R +x scripts/*.sh tests/integration/*.sh 2>/dev/null || true

      - name: Run CI validation
        run: |
          ./scripts/ci-validate-security-alert.sh | tee ci-validate-results.txt
          exit ${PIPESTATUS[0]}

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ci-validate-results
          path: ci-validate-results.txt
          retention-days: 7
          if-no-files-found: ignore

  validate-docs:
    name: Validate Docs
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Validate docs structure
        run: |
          ERRORS=0
          for doc in README.md; do
            if [ ! -f "$doc" ]; then
              echo "❌ Missing: $doc"
              ERRORS=$((ERRORS + 1))
            else
              echo "✅ Found: $doc"
            fi
          done
          for dir in security_alert security_alert/default security_alert/bin; do
            if [ ! -d "$dir" ]; then
              echo "❌ Missing dir: $dir/"
              ERRORS=$((ERRORS + 1))
            else
              echo "✅ Found dir: $dir/"
            fi
          done
          for cfg in security_alert/default/savedsearches.conf security_alert/default/macros.conf security_alert/default/app.conf; do
            if [ ! -f "$cfg" ]; then
              echo "❌ Missing config: $cfg"
              ERRORS=$((ERRORS + 1))
            else
              echo "✅ Found config: $cfg"
            fi
          done
          [ $ERRORS -eq 0 ] || exit 1

  validate-pre-commit:
    name: Pre-commit Checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Run pre-commit
        run: |
          pip install pre-commit -q
          pre-commit run --all-files --show-diff-on-failure

  validate-spl:
    name: Validate SPL
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Validate SPL queries
        run: |
          ERRORS=0

          # Check savedsearches.conf
          CONF="security_alert/default/savedsearches.conf"
          if [ -f "$CONF" ]; then
            STANZAS=$(grep -c '^\[' "$CONF")
            echo "✅ savedsearches.conf: $STANZAS stanzas"

            # Verify all search stanzas have a 'search' key
            SEARCH_COUNT=$(grep -c '^search\s*=' "$CONF" || echo "0")
            if [ "$SEARCH_COUNT" -eq 0 ]; then
              echo "❌ No search= definitions found in savedsearches.conf"
              ERRORS=$((ERRORS + 1))
            else
              echo "✅ Found $SEARCH_COUNT search definitions"
            fi

            # Check for alert action references
            ACTIONS=$(grep -c '^action\.' "$CONF" || echo "0")
            echo "ℹ️  Found $ACTIONS alert action configurations"
          else
            echo "❌ Missing: $CONF"
            ERRORS=$((ERRORS + 1))
          fi

          # Check macros.conf
          CONF="security_alert/default/macros.conf"
          if [ -f "$CONF" ]; then
            STANZAS=$(grep -c '^\[' "$CONF")
            echo "✅ macros.conf: $STANZAS stanzas"

            # Verify macros have definitions
            DEFS=$(grep -c '^definition\s*=' "$CONF" || echo "0")
            if [ "$DEFS" -eq 0 ]; then
              echo "❌ No definition= found in macros.conf"
              ERRORS=$((ERRORS + 1))
            else
              echo "✅ Found $DEFS macro definitions"
            fi
          else
            echo "❌ Missing: $CONF"
            ERRORS=$((ERRORS + 1))
          fi

          [ $ERRORS -eq 0 ] || exit 1

  security-sast:
    name: SAST Scan
    runs-on: ubuntu-latest
    continue-on-error: true  # Non-blocking: SAST may have false positives
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Run Semgrep
        run: |
          pip install semgrep -q
          semgrep scan --config auto --config p/python \
            --exclude third_party --exclude node_modules --exclude python/lib \
            --exclude extras --exclude .cache \
            --json --output semgrep-results.json .
          echo "Scan complete"

      - name: Upload SAST results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: semgrep-results
          path: semgrep-results.json
          retention-days: 7
          if-no-files-found: ignore

  security-secrets:
    name: Secret Detection
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Detect secrets
        run: |
          pip install detect-secrets -q
          detect-secrets scan --exclude-files 'third_party/.*' \
            --exclude-files 'node_modules/.*' \
            --exclude-files 'python/lib/.*' \
            --exclude-files 'extras/.*' \
            --exclude-files '\.cache/.*' \
            --exclude-files '.*\.json$' \
            . > secrets-results.json 2>&1
          SECRETS=$(grep -c '"is_secret": true' secrets-results.json 2>/dev/null || echo "0")
          echo "Secrets found: $SECRETS"
          if [ "$SECRETS" -gt 0 ]; then
            echo "::error::Detected $SECRETS potential secrets in codebase"
            exit 1
          fi

      - name: Upload secrets results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: secrets-results
          path: secrets-results.json
          retention-days: 7
          if-no-files-found: ignore

  security-dependency:
    name: Dependency Audit
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main'
    continue-on-error: true  # Non-blocking: reports dependency vulnerabilities
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Audit dependencies
        run: |
          pip install pip-audit -q
          if [ -f requirements.txt ]; then
            pip-audit -r requirements.txt --format json -o pip-audit.json
            echo "Vulnerabilities: $(grep -c '"id":' pip-audit.json 2>/dev/null || echo "0")"
          else
            echo "No requirements.txt"
          fi

      - name: Upload dependency results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dependency-audit
          path: pip-audit.json
          retention-days: 7
          if-no-files-found: ignore

  security-sbom:
    name: Generate SBOM
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main'
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Generate SBOM
        run: |
          pip install cyclonedx-bom -q
          if [ -f requirements.txt ]; then
            cyclonedx-py requirements requirements.txt -o sbom-python.json --format json 2>/dev/null || true
          else
            echo '{"bomFormat": "CycloneDX", "specVersion": "1.4", "components": []}' > sbom-python.json
          fi

      - name: Upload SBOM
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sbom
          path: sbom-*.json
          retention-days: 30
          if-no-files-found: ignore

  test-unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [validate-syntax, validate-pre-commit]
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pytest pytest-cov -q

      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short \
            --cov=security_alert/bin --cov-report=xml:coverage-unit.xml \
            --cov-report=term 2>&1 | tee unit-results.txt
          exit ${PIPESTATUS[0]}

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: |
            unit-results.txt
            coverage-unit.xml
          retention-days: 7

  test-e2e:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [validate-syntax, validate-pre-commit]
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pytest pytest-cov requests -q

      - name: Run E2E tests (no live Splunk)
        run: |
          pytest tests/e2e/ -v --tb=short \
            -m "not splunk_live" \
            --cov=security_alert/bin --cov-report=xml:coverage-e2e.xml \
            --cov-report=term 2>&1 | tee e2e-results.txt
          exit ${PIPESTATUS[0]}

      - name: Upload E2E results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            e2e-results.txt
            coverage-e2e.xml
          retention-days: 7
          if-no-files-found: ignore

  # NOTE: test-integration job removed — scripts/validate-deployment.sh does not exist
  # TODO: Create validate-deployment.sh and re-enable when integration testing is needed

  coverage-report:
    name: Coverage Report
    runs-on: ubuntu-latest
    needs: [test-e2e]
    if: always()
    steps:
      - name: Download E2E coverage
        uses: actions/download-artifact@v4
        with:
          name: e2e-test-results
          path: ./e2e
        continue-on-error: true

      - name: Summary
        run: |
          echo "## Test Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f e2e/coverage-e2e.xml ]; then
            echo "✅ E2E test coverage: Available" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ E2E test coverage: Not available" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f e2e/e2e-results.txt ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### E2E Test Results" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 e2e/e2e-results.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

  validate-frontend:
    name: Frontend Build
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: false

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Lint
        run: npm run lint --if-present

      - name: Build
        run: npm run build
