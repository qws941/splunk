# Splunk Correlation Rules - Advanced Threat Detection
# Location: $SPLUNK_HOME/etc/apps/fortigate/local/correlation-rules.conf
#
# Phase 4.1 - Advanced Correlation Engine
# Combines multiple weak signals into strong threat indicators for automated response
#
# Architecture:
# - Correlation searches run every 5-15 minutes
# - Results stored in summary_fw index with marker="correlation_detection"
# - High-confidence detections trigger automated FortiGate blocking (Phase 3.2)
# - Low-confidence detections generate Slack alerts for analyst review
#
# Installation:
# 1. Ensure Phase 3.1 (Threat Intelligence) is operational
# 2. Ensure Phase 3.2 (Automated Response) is configured
# 3. Ensure Phase 3.3 (Data Model) is accelerated
# 4. Copy this file to savedsearches.conf or merge contents
# 5. Reload Splunk: splunk restart splunkweb
#
# Phase 4.1 - Advanced Correlation Rules

# ============================================================================
# Rule 1: Multi-Factor Threat Score
# ============================================================================
# Combines: abuse_score + failed logins + geo-location risk + event frequency
# Threshold: correlation_score >= 75 (out of 100)
# Action: Auto-block if score >= 90, Alert if 75-89

[Correlation_Multi_Factor_Threat_Score]
description = Detect threats by correlating abuse_score, failed logins, geo-location, and event frequency
search = | datamodel Fortinet_Security Security_Events search \
| lookup abuseipdb_lookup.csv ip AS src_ip OUTPUT abuse_score, country, isp \
| eval geo_risk = case( \
    country IN ("CN", "RU", "KP", "IR"), 50, \
    country IN ("VN", "BR", "IN"), 30, \
    country IN ("US", "GB", "DE", "JP", "KR"), 0, \
    1=1, 20 \
  ) \
| eval abuse_component = coalesce(abuse_score, 0) * 0.4 \
| eval geo_component = geo_risk * 0.2 \
| eval login_failures = if(match(msg, "(?i)(failed.*login|authentication.*fail|invalid.*credential)"), 30, 0) \
| eval frequency_component = case( \
    event_count > 100, 30, \
    event_count > 50, 20, \
    event_count > 10, 10, \
    1=1, 0 \
  ) \
| eval correlation_score = round(abuse_component + geo_component + login_failures + frequency_component, 2) \
| where correlation_score >= 75 \
| stats count as event_count, \
    avg(correlation_score) as avg_correlation_score, \
    max(correlation_score) as max_correlation_score, \
    values(abuse_score) as abuse_scores, \
    values(country) as countries, \
    values(isp) as isps, \
    sum(eval(if(match(msg, "(?i)failed.*login"), 1, 0))) as failed_login_count, \
    values(dst_ip) as target_ips, \
    values(service) as services \
  by src_ip, _time span=1h \
| eval action_recommendation = case( \
    max_correlation_score >= 90, "AUTO_BLOCK", \
    max_correlation_score >= 80, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Multi-Factor Threat Score" \
| collect index=summary_fw addtime=true marker="correlation_detection=multi_factor_threat"

# Schedule: Every 15 minutes
cron_schedule = */15 * * * *
enableSched = 1

dispatch.earliest_time = -15m
dispatch.latest_time = now

# Alert on AUTO_BLOCK recommendations
alert.track = 1
alert.condition = search max_correlation_score >= 90
alert.severity = 4
alert.suppress = 0

# Trigger automated blocking script
action.script = 1
action.script.filename = fortigate_auto_block.py
action.script.track_alert = 1

# ============================================================================
# Rule 2: Repeated High-Risk Events (Time-Series Correlation)
# ============================================================================
# Detects: Same source IP with risk_score > 70 appearing multiple times within 1 hour
# Threshold: >= 3 high-risk events within 60 minutes
# Leverages: Data model's calculated risk_score field (Phase 3.3)

[Correlation_Repeated_High_Risk_Events]
description = Detect repeated high-risk events from same source within 1 hour using data model risk_score
search = | tstats count as event_count, \
    latest(_time) as latest_event, \
    earliest(_time) as earliest_event, \
    values(Security_Events.severity) as severities, \
    values(Security_Events.attack_type) as attack_types, \
    values(Security_Events.dst_ip) as target_ips, \
    values(Security_Events.service) as services \
  WHERE datamodel=Fortinet_Security.Security_Events \
    Security_Events.risk_score > 70 \
  BY Security_Events.src_ip _time span=1h \
| where event_count >= 3 \
| eval time_window = tostring(latest_event - earliest_event, "duration") \
| eval correlation_score = case( \
    event_count >= 10, 95, \
    event_count >= 7, 85, \
    event_count >= 5, 75, \
    event_count >= 3, 65, \
    1=1, 50 \
  ) \
| lookup abuseipdb_lookup.csv ip AS Security_Events.src_ip OUTPUT abuse_score, country \
| eval correlation_score = correlation_score + if(abuse_score > 80, 5, 0) \
| eval action_recommendation = case( \
    correlation_score >= 90, "AUTO_BLOCK", \
    correlation_score >= 75, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Repeated High-Risk Events" \
| rename Security_Events.src_ip as src_ip \
| collect index=summary_fw addtime=true marker="correlation_detection=repeated_high_risk"

cron_schedule = */10 * * * *
enableSched = 1

dispatch.earliest_time = -1h
dispatch.latest_time = now

alert.track = 1
alert.condition = search correlation_score >= 90
alert.severity = 4

action.script = 1
action.script.filename = fortigate_auto_block.py

# ============================================================================
# Rule 3: Low Abuse Score + Suspicious Behavior
# ============================================================================
# Detects: Weak signals that combine into strong indicator
# Pattern: abuse_score 40-60 + failed login attempts + port scanning behavior
# Threshold: 3+ signals present simultaneously

[Correlation_Weak_Signal_Combination]
description = Correlate weak signals (low abuse score + failed logins + scanning) into strong threat indicator
search = index=fw earliest=-15m latest=now \
| lookup abuseipdb_lookup.csv ip AS src_ip OUTPUT abuse_score, country, isp \
| eval has_low_abuse_score = if(abuse_score >= 40 AND abuse_score <= 60, 1, 0) \
| eval has_failed_login = if(match(msg, "(?i)(failed.*login|authentication.*fail|brute.*force)"), 1, 0) \
| eval has_port_scan = if(match(msg, "(?i)(port.*scan|reconnaissance|probe)"), 1, 0) \
| eval has_multiple_targets = if(dc(dst_ip) > 5, 1, 0) \
| eval has_high_frequency = if(count > 20, 1, 0) \
| stats sum(has_low_abuse_score) as signal_abuse, \
    sum(has_failed_login) as signal_failed_login, \
    sum(has_port_scan) as signal_port_scan, \
    sum(has_multiple_targets) as signal_multiple_targets, \
    sum(has_high_frequency) as signal_high_frequency, \
    count as event_count, \
    dc(dst_ip) as unique_targets, \
    values(dst_ip) as target_ips, \
    values(service) as services, \
    values(abuse_score) as abuse_scores, \
    values(country) as countries \
  by src_ip \
| eval weak_signals_count = signal_abuse + signal_failed_login + signal_port_scan + signal_multiple_targets + signal_high_frequency \
| where weak_signals_count >= 3 \
| eval correlation_score = case( \
    weak_signals_count >= 5, 95, \
    weak_signals_count >= 4, 85, \
    weak_signals_count >= 3, 75, \
    1=1, 50 \
  ) \
| eval action_recommendation = case( \
    correlation_score >= 90, "AUTO_BLOCK", \
    correlation_score >= 75, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Weak Signal Combination" \
| eval detected_signals = mvjoin(if(signal_abuse=1, "low_abuse_score", null()) + \
                                  if(signal_failed_login=1, "failed_login", null()) + \
                                  if(signal_port_scan=1, "port_scan", null()) + \
                                  if(signal_multiple_targets=1, "multiple_targets", null()) + \
                                  if(signal_high_frequency=1, "high_frequency", null()), ", ") \
| collect index=summary_fw addtime=true marker="correlation_detection=weak_signal_combo"

cron_schedule = */5 * * * *
enableSched = 1

dispatch.earliest_time = -15m
dispatch.latest_time = now

alert.track = 1
alert.condition = search weak_signals_count >= 3
alert.severity = 3

action.slack = 1
action.slack.param.channel = #splunk-alerts
action.slack.param.message = Weak Signal Correlation Detected: $result.src_ip$ ($result.weak_signals_count$ signals: $result.detected_signals$)

# ============================================================================
# Rule 4: Geo-Location Risk + Attack Pattern
# ============================================================================
# Detects: High-risk countries + known attack patterns
# Pattern: Source from CN/RU/KP/IR + intrusion attempt or malware detection
# Auto-block if both conditions met

[Correlation_Geo_Attack_Pattern]
description = Correlate high-risk geo-location with attack patterns for automated blocking
search = | datamodel Fortinet_Security Security_Events search earliest=-15m \
| lookup abuseipdb_lookup.csv ip AS src_ip OUTPUT abuse_score, country, isp \
| eval is_high_risk_country = if(country IN ("CN", "RU", "KP", "IR", "BY"), 1, 0) \
| eval is_attack_pattern = if(attack_type IN ("intrusion_attempt", "malware_detected", "data_exfiltration", "web_attack"), 1, 0) \
| eval is_critical_severity = if(severity="critical", 1, 0) \
| where is_high_risk_country=1 AND (is_attack_pattern=1 OR is_critical_severity=1) \
| stats count as event_count, \
    sum(is_attack_pattern) as attack_events, \
    sum(is_critical_severity) as critical_events, \
    dc(dst_ip) as unique_targets, \
    values(attack_type) as attack_types, \
    values(severity) as severities, \
    values(dst_ip) as target_ips, \
    values(service) as services, \
    values(abuse_score) as abuse_scores, \
    values(isp) as isps, \
    latest(risk_score) as max_risk_score \
  by src_ip, country \
| eval correlation_score = 60 + \
    if(attack_events > 0, 20, 0) + \
    if(critical_events > 0, 15, 0) + \
    if(max_risk_score > 80, 10, 0) + \
    if(unique_targets > 5, 5, 0) \
| where correlation_score >= 75 \
| eval action_recommendation = case( \
    correlation_score >= 90 OR (attack_events > 0 AND critical_events > 0), "AUTO_BLOCK", \
    correlation_score >= 80, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Geo-Location + Attack Pattern" \
| collect index=summary_fw addtime=true marker="correlation_detection=geo_attack_pattern"

cron_schedule = */5 * * * *
enableSched = 1

dispatch.earliest_time = -15m
dispatch.latest_time = now

alert.track = 1
alert.condition = search correlation_score >= 90 OR (attack_events > 0 AND critical_events > 0)
alert.severity = 5

action.script = 1
action.script.filename = fortigate_auto_block.py

# ============================================================================
# Rule 5: Time-Based Anomaly Correlation
# ============================================================================
# Detects: Unusual activity patterns (e.g., activity from typically quiet IPs)
# Uses: Summary index hourly traffic data (Phase 3.3)
# Pattern: IP with <10 events/hour average suddenly shows >100 events/hour

[Correlation_Time_Based_Anomaly]
description = Detect anomalous activity spikes using summary index baseline
search = | tstats count as current_hour_count \
  WHERE datamodel=Fortinet_Security.Security_Events earliest=-1h latest=now \
  BY Security_Events.src_ip \
| rename Security_Events.src_ip as src_ip \
| join type=left src_ip [ \
    search index=summary_fw search_name="Fortinet_Hourly_Traffic_Summary" earliest=-7d latest=-1h \
    | stats avg(session_count) as avg_hourly_count, \
        stdev(session_count) as stdev_hourly_count, \
        max(session_count) as max_hourly_count \
      by src_ip \
  ] \
| eval baseline_count = coalesce(avg_hourly_count, 0) \
| eval stdev = coalesce(stdev_hourly_count, 1) \
| eval z_score = round((current_hour_count - baseline_count) / stdev, 2) \
| eval spike_ratio = round(current_hour_count / if(baseline_count > 0, baseline_count, 1), 2) \
| where z_score > 3 AND spike_ratio > 10 \
| lookup abuseipdb_lookup.csv ip AS src_ip OUTPUT abuse_score, country \
| eval correlation_score = case( \
    z_score > 5 AND spike_ratio > 50, 95, \
    z_score > 4 AND spike_ratio > 20, 85, \
    z_score > 3 AND spike_ratio > 10, 75, \
    1=1, 60 \
  ) + if(abuse_score > 70, 5, 0) \
| eval action_recommendation = case( \
    correlation_score >= 90, "AUTO_BLOCK", \
    correlation_score >= 80, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Time-Based Anomaly" \
| fields src_ip, current_hour_count, baseline_count, z_score, spike_ratio, correlation_score, action_recommendation, abuse_score, country, correlation_rule \
| collect index=summary_fw addtime=true marker="correlation_detection=time_anomaly"

cron_schedule = */15 * * * *
enableSched = 1

dispatch.earliest_time = -1h
dispatch.latest_time = now

alert.track = 1
alert.condition = search correlation_score >= 85
alert.severity = 4

action.script = 1
action.script.filename = fortigate_auto_block.py

# ============================================================================
# Rule 6: Cross-Event Type Correlation
# ============================================================================
# Detects: Multiple different attack types from same source within short time
# Pattern: Same IP shows intrusion attempt + port scan + brute force within 1 hour
# Indicates sophisticated attacker with multiple tactics

[Correlation_Cross_Event_Type]
description = Detect multiple attack types from same source indicating sophisticated threat
search = | datamodel Fortinet_Security Security_Events search earliest=-1h \
| where attack_type != "other" \
| stats dc(attack_type) as unique_attack_types, \
    count as event_count, \
    values(attack_type) as attack_types, \
    values(severity) as severities, \
    values(dst_ip) as target_ips, \
    values(service) as services, \
    max(risk_score) as max_risk_score \
  by src_ip, _time span=1h \
| where unique_attack_types >= 3 \
| lookup abuseipdb_lookup.csv ip AS src_ip OUTPUT abuse_score, country, isp \
| eval correlation_score = case( \
    unique_attack_types >= 5, 95, \
    unique_attack_types >= 4, 85, \
    unique_attack_types >= 3, 75, \
    1=1, 60 \
  ) + if(max_risk_score > 80, 10, 0) + if(abuse_score > 70, 5, 0) \
| eval action_recommendation = case( \
    correlation_score >= 90, "AUTO_BLOCK", \
    correlation_score >= 80, "REVIEW_AND_BLOCK", \
    1=1, "MONITOR" \
  ) \
| eval correlation_rule = "Cross-Event Type Correlation" \
| eval threat_profile = "Sophisticated Attacker (" + unique_attack_types + " tactics: " + mvjoin(attack_types, ", ") + ")" \
| collect index=summary_fw addtime=true marker="correlation_detection=cross_event_type"

cron_schedule = */10 * * * *
enableSched = 1

dispatch.earliest_time = -1h
dispatch.latest_time = now

alert.track = 1
alert.condition = search unique_attack_types >= 3
alert.severity = 5

action.script = 1
action.script.filename = fortigate_auto_block.py

action.slack = 1
action.slack.param.channel = #splunk-alerts
action.slack.param.message = Sophisticated Threat Detected: $result.src_ip$ - $result.threat_profile$ (Score: $result.correlation_score$)

# ============================================================================
# Master Correlation View (Dashboard Query)
# ============================================================================
# Aggregates all correlation detections for unified monitoring
# Not scheduled - used by dashboard panels

[Correlation_Master_View]
description = Unified view of all correlation detections for dashboard
search = index=summary_fw marker="correlation_detection=*" earliest=-24h \
| rex field=marker "correlation_detection=(?<correlation_type>.*)" \
| stats count as detection_count, \
    latest(_time) as last_detected, \
    avg(correlation_score) as avg_score, \
    max(correlation_score) as max_score, \
    sum(eval(if(action_recommendation="AUTO_BLOCK", 1, 0))) as auto_blocks, \
    sum(eval(if(action_recommendation="REVIEW_AND_BLOCK", 1, 0))) as review_required, \
    sum(eval(if(action_recommendation="MONITOR", 1, 0))) as monitoring, \
    values(src_ip) as affected_ips, \
    values(correlation_rule) as rules_triggered \
  by correlation_type, src_ip \
| sort - max_score

enableSched = 0

# ============================================================================
# IMPORTANT NOTES
# ============================================================================
#
# 1. Correlation Score Calculation:
#    - Base score: 0-100 scale
#    - Components: Abuse score (40%), Geo risk (20%), Behavior (40%)
#    - Thresholds: 90+ = AUTO_BLOCK, 80-89 = REVIEW, 75-79 = MONITOR
#
# 2. Auto-Block Integration (Phase 3.2):
#    - action.script.filename = fortigate_auto_block.py
#    - Script receives correlation results via stdin
#    - Only executes when correlation_score >= 90
#    - Respects IP whitelist from Phase 3.2
#
# 3. Summary Index Storage:
#    - All detections â†’ summary_fw index
#    - Marker field: correlation_detection=<rule_type>
#    - Retention: 90 days (configurable in indexes.conf)
#
# 4. Performance Impact:
#    - Correlation searches use tstats (fast)
#    - Summary index lookups (faster than raw data)
#    - Expected CPU overhead: <5%
#
# 5. False Positive Management:
#    - Whitelist IPs in fortigate_whitelist.csv (Phase 3.2)
#    - Adjust correlation_score thresholds per rule
#    - Review REVIEW_AND_BLOCK recommendations before enabling auto-block
#
# 6. Testing Procedure:
#    ```bash
#    # Run correlation search manually
#    splunk search "| savedsearch Correlation_Multi_Factor_Threat_Score"
#
#    # Check summary index
#    index=summary_fw marker="correlation_detection=*" | stats count by correlation_type
#
#    # Monitor auto-block actions
#    index=_internal source=*fortigate_auto_block.log
#    ```
#
# 7. Monitoring Correlation Health:
#    ```spl
#    index=_internal source=*scheduler.log savedsearch_name="Correlation_*"
#    | stats avg(run_time) as avg_runtime, max(run_time) as max_runtime by savedsearch_name
#    ```
#
# 8. Tuning Guidelines:
#    - Start with conservative thresholds (higher correlation_score)
#    - Enable AUTO_BLOCK only after 2-week monitoring period
#    - Review false positives weekly
#    - Adjust weak signal weights based on environment
#
# ============================================================================
